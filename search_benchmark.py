import json
import mmap
import random
import sys
import os
from bangumi_archive.local_archive_searcher import search_all_data, _search_all_data_with_index

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.pathï¼Œç¡®ä¿å¯ä»¥å¯¼å…¥æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# é…ç½®
file_path = "archivedata/subject.jsonlines"
samples_size = 200
is_save_report = False


def sample_subjects(input_file, sample_size: int, output_file=None):
    if sample_size <= 0:
        raise ValueError("sample_size å¿…é¡»å¤§äº 0")
    file_size = os.path.getsize(input_file)
    if file_size == 0:
        raise ValueError("æ–‡ä»¶ä¸ºç©º")
    offsets = []
    print("æ­£åœ¨æ‰«ææ–‡ä»¶ï¼Œæ„å»ºè¡Œåç§»ç´¢å¼•...")
    with open(input_file, 'rb') as f:
        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
            pos = 0
            while pos < len(mm):
                next_pos = mm.find(b'\n', pos)
                if next_pos == -1:
                    offsets.append(pos)
                    break
                offsets.append(pos)
                pos = next_pos + 1
    total_lines = len(offsets)
    print(f"å…±æ‰¾åˆ° {total_lines} è¡Œ")
    if sample_size > total_lines:
        print(f"è­¦å‘Šï¼šè¯·æ±‚é‡‡æ · {sample_size} è¡Œï¼Œä½†æ–‡ä»¶åªæœ‰ {total_lines} è¡Œï¼Œå°†é‡‡æ ·å…¨éƒ¨è¡Œ")
        sample_size = total_lines
    sampled_indices = random.sample(range(total_lines), sample_size)
    print(f"å·²éšæœºé‡‡æ · {sample_size} è¡Œç´¢å¼•")
    samples = []
    print("æ­£åœ¨è¯»å–é‡‡æ ·è¡Œ...")
    with open(input_file, 'rb') as f:
        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
            for idx in sampled_indices:
                start = offsets[idx]
                end = offsets[idx + 1] if idx + 1 < total_lines else len(mm)
                line_bytes = mm[start:end]
                line_str = line_bytes.rstrip(b'\n\r').decode('utf-8')
                samples.append(json.loads(line_str))
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as out_f:
            for item in samples:
                out_f.write(json.dumps(item, ensure_ascii=False) + '\n')
        print(f"é‡‡æ ·ç»“æœå·²å†™å…¥ {output_file}")
        return None
    else:
        return samples


def evaluate_search_function(
    file_path: str,
    sample_size: int,
    search_func,
    is_save_report: bool = False
):
    """
    åŠ¨æ€è¯„ä¼°ä»»æ„æœç´¢å‡½æ•°çš„å¬å›æ•ˆæœã€‚
    :param file_path: æ•°æ®æ–‡ä»¶è·¯å¾„ (.jsonlines)
    :param sample_size: é‡‡æ ·æ•°é‡
    :param search_func: è¦æµ‹è¯•çš„æœç´¢å‡½æ•°ï¼Œå¿…é¡»æ¥å— (file_path, query) ä¸¤ä¸ªå‚æ•°
    :param is_save_report: æ˜¯å¦ä¿å­˜è¯„ä¼°ç»“æœåˆ° JSON
    """
    print("ğŸ” å¼€å§‹é‡‡æ ·...")
    data_samples = sample_subjects(file_path, sample_size)
    print(f"âœ… é‡‡æ ·å®Œæˆï¼Œå…± {len(data_samples)} æ¡è®°å½•\n")

    # æ„å»º query-ground truth å¯¹
    query_gt_pairs = []
    for item in data_samples:
        name_cn = item.get("name_cn", "").strip()
        name = item.get("name", "").strip()
        item_id = item.get("id")
        query = name_cn if name_cn else name
        if not query:
            continue
        query_gt_pairs.append({
            "query": query,
            "ground_truth_id": item_id,
        })
    print(f"ğŸ“Œ æˆåŠŸæ„å»º {len(query_gt_pairs)} ä¸ª query-ground truth å¯¹")
    if query_gt_pairs:
        print(
            f"ç¤ºä¾‹ query: '{query_gt_pairs[0]['query']}' (ID: {query_gt_pairs[0]['ground_truth_id']})\n")

    # æ‰§è¡Œæœç´¢è¯„ä¼°
    results_per_query = []
    tp_query_count = 0  # query-level recall è®¡æ•°
    tp_total = 0        # result-level precision è®¡æ•°
    fp_total = 0
    total_queries = len(query_gt_pairs)

    print(f"ğŸ” å¼€å§‹å¯¹æ¯ä¸ª query æ‰§è¡Œæ£€ç´¢ï¼ˆä½¿ç”¨å‡½æ•°: {search_func.__name__}ï¼‰...")
    for i, pair in enumerate(query_gt_pairs, 1):
        query = pair["query"]
        gt_id = pair["ground_truth_id"]

        search_results = search_func(file_path, query)
        returned_ids = [r.get("id") for r in search_results]

        # Query-level recall
        found_in_results = gt_id in returned_ids
        if found_in_results:
            tp_query_count += 1

        # Result-level precision
        tp_total += sum(1 for rid in returned_ids if rid == gt_id)
        fp_total += sum(1 for rid in returned_ids if rid != gt_id)

        results_per_query.append({
            "query": query,
            "gt_id": gt_id,
            "found": found_in_results,
            "search_results_count": len(returned_ids),
            "search_results_ids": returned_ids
        })

        if i % 100 == 0:
            print(f"  å·²å¤„ç† {i}/{total_queries}ï¼Œå·²å¬å› {tp_query_count} æ¡")

    # è®¡ç®—æŒ‡æ ‡
    recall = tp_query_count / total_queries if total_queries > 0 else 0.0
    precision = tp_total / \
        (tp_total + fp_total) if (tp_total + fp_total) > 0 else 0.0
    f1 = 2 * (precision * recall) / (precision +
                                     recall) if (precision + recall) > 0 else 0.0

    # Top-1 Accuracy
    top1_correct = sum(
        1 for r in results_per_query if r["search_results_ids"] and r["search_results_ids"][0] == r["gt_id"])
    top1_accuracy = top1_correct / total_queries if total_queries > 0 else 0.0

    print("\n" + "="*70)
    print("ğŸ“Š è¯„ä¼°æŠ¥å‘Š")
    print("="*70)
    print(f"æœç´¢å‡½æ•°: {search_func.__module__}.{search_func.__name__}")
    print(f"æ€»æŸ¥è¯¢æ•°: {total_queries}")
    print(f"æˆåŠŸå¬å› (TP): {tp_query_count}")
    print(f"æœªå¬å› (FN): {total_queries - tp_query_count}")
    print(
        f"å¹³å‡æ£€ç´¢ç»“æœæ•°: {sum(r['search_results_count'] for r in results_per_query) / total_queries:.2f}")
    print(f"å¬å›ç‡ (Recall): {recall:.4f} ({tp_query_count}/{total_queries})")
    print(f"ç²¾ç¡®ç‡ (Precision): {precision:.4f}")
    print(f"Top-1 å‡†ç¡®ç‡: {top1_accuracy:.4f}")
    print(f"F1-score: {f1:.4f}")
    print("="*70)

    # é”™è¯¯æ ·ä¾‹
    failed_queries = [r for r in results_per_query if not r["found"]][:5]
    print(f"\nâŒ å‰ 5 ä¸ªæœªå¬å›çš„æŸ¥è¯¢ï¼ˆFNï¼‰:")
    for i, r in enumerate(failed_queries, 1):
        print(f"  {i}. Query: '{r['query']}' (ID: {r['gt_id']})")
        print(f"     æ£€ç´¢ç»“æœæ•°: {r['search_results_count']}")
        if r['search_results_ids']:
            ids_str = r['search_results_ids'][:3]
            suffix = "..." if len(r['search_results_ids']) > 3 else ""
            print(f"     è¿”å›çš„ ID: {ids_str}{suffix}")

    # ä¿å­˜æŠ¥å‘Š
    if is_save_report:
        output_eval = {
            "total_queries": total_queries,
            "tp_count": tp_query_count,
            "recall": recall,
            "precision": precision,
            "f1": f1,
            "top1_accuracy": top1_accuracy,
            "search_function": f"{search_func.__module__}.{search_func.__name__}",
            "failed_queries": [
                {
                    "query": r["query"],
                    "gt_id": r["gt_id"],
                    "search_results_count": r["search_results_count"],
                    "search_results_ids": r["search_results_ids"]
                }
                for r in failed_queries
            ]
        }
        eval_file = "evaluation_results.json"
        with open(eval_file, 'w', encoding='utf-8') as f:
            json.dump(output_eval, f, ensure_ascii=False, indent=2)
        print(f"\n è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: {eval_file}")

    return {
        "recall": recall,
        "precision": precision,
        "f1": f1,
        "top1_accuracy": top1_accuracy,
        "search_function": f"{search_func.__module__}.{search_func.__name__}",
        "total_queries": total_queries,
        "tp_count": tp_query_count
    }


if __name__ == "__main__":
    # æµ‹è¯• search_all_data
    # print("\næµ‹è¯• search_all_data")
    # evaluate_search_function(
    #     file_path=file_path,
    #     sample_size=samples_size,
    #     search_func=search_all_data,
    #     is_save_report=is_save_report
    # )
    print("\næµ‹è¯• _search_all_data_with_index")
    evaluate_search_function(
        file_path=file_path,
        sample_size=samples_size,
        search_func=_search_all_data_with_index,
        is_save_report=is_save_report
    )
